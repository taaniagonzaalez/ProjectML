{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324e8a16",
   "metadata": {},
   "source": [
    "# üêç Machine Learning Project Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183be9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd12ce1",
   "metadata": {},
   "source": [
    "# 1. Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d76f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_csv(\"train.csv\", sep=',')\n",
    "df_train_raw[\"edgelist\"].head(1)\n",
    "df_train_raw[\"edgelist\"] = df_train_raw[\"edgelist\"].apply(ast.literal_eval)\n",
    "\n",
    "df_test_raw = pd.read_csv(\"test.csv\", sep=',')\n",
    "df_test_raw[\"edgelist\"].head(1)\n",
    "df_test_raw[\"edgelist\"] = df_test_raw[\"edgelist\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536ab68",
   "metadata": {},
   "source": [
    "# 2. Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4dd84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from community import community_louvain  # pip install python-louvain\n",
    "\n",
    "def normalize_group(df_group):\n",
    "    numeric_cols = [\n",
    "        'degree', 'closeness', 'betweenness', 'pagerank',\n",
    "        'eigenvector', 'katz', 'load',\n",
    "        'eccentricity', 'avg_neighbor_degree',\n",
    "         'community', 'is_leaf'\n",
    "        #'shortest_path_length', 'is_leaf', 'neighbor_connectivity'\n",
    "    ]\n",
    "    scaler = MinMaxScaler()\n",
    "    df_group[numeric_cols] = scaler.fit_transform(df_group[numeric_cols])\n",
    "    return df_group\n",
    "\n",
    "def pre_processing(data):\n",
    "    training_data = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        edgelist = row[\"edgelist\"]\n",
    "        \n",
    "        # Create undirected graph\n",
    "        T = nx.Graph()\n",
    "        T.add_edges_from(edgelist)\n",
    "\n",
    "        if not nx.is_connected(T):\n",
    "            continue\n",
    "        \n",
    "        root_node = row.get(\"root\", None)\n",
    "        \n",
    "        # Compute centralities\n",
    "        closeness = nx.closeness_centrality(T)\n",
    "        betweenness = nx.betweenness_centrality(T)\n",
    "        pagerank = nx.pagerank(T, max_iter=1000)\n",
    "        \n",
    "        # Additional centrality measures with fallbacks\n",
    "        try:\n",
    "            eigenvector = nx.eigenvector_centrality(T, max_iter=10000, tol=1e-06)\n",
    "        except nx.PowerIterationFailedConvergence:\n",
    "            eigenvector = {n: 0.0 for n in T.nodes}\n",
    "            \n",
    "        try:\n",
    "            katz = nx.katz_centrality(T, alpha=0.1)\n",
    "        except nx.NetworkXException:\n",
    "            katz = {n: 0.0 for n in T.nodes}\n",
    "            \n",
    "        try:\n",
    "            load = nx.load_centrality(T)\n",
    "        except:\n",
    "            load = {n: 0.0 for n in T.nodes}\n",
    "\n",
    "        # Structural properties\n",
    "        degree = dict(T.degree())\n",
    "        eccentricity = nx.eccentricity(T)\n",
    "        avg_neighbor_degree = nx.average_neighbor_degree(T)\n",
    "        \n",
    "        # Community detection\n",
    "        partition = community_louvain.best_partition(T)\n",
    "        \n",
    "        for v in T.nodes:\n",
    "            features = {\n",
    "                \"sentence\": row[\"sentence\"],\n",
    "                \"language\": row[\"language\"],\n",
    "                \"n\": row[\"n\"],\n",
    "                \"node\": v,\n",
    "\n",
    "                # Centrality measures\n",
    "                \"degree\": degree[v],\n",
    "                \"closeness\": closeness[v],\n",
    "                \"betweenness\": betweenness[v],\n",
    "                \"pagerank\": pagerank[v],\n",
    "                \"eigenvector\": eigenvector[v],\n",
    "                \"katz\": katz[v],\n",
    "                \"load\": load[v],\n",
    "\n",
    "                # Structural properties\n",
    "                \"eccentricity\": eccentricity[v],\n",
    "                \"avg_neighbor_degree\": avg_neighbor_degree[v],\n",
    "\n",
    "                # Community information\n",
    "                \"community\": partition[v],\n",
    "\n",
    "                \"is_leaf\": 1 if T.degree(v) == 1 else 0,\n",
    "            }\n",
    "\n",
    "            if \"id\" in row:\n",
    "                features[\"id\"] = row[\"id\"]\n",
    "\n",
    "            if root_node is not None:\n",
    "                features[\"is_root\"] = 1 if v == root_node else 0\n",
    "\n",
    "            training_data.append(features)\n",
    "\n",
    "    training_data = pd.DataFrame(training_data)\n",
    "    \n",
    "    # Normalize features by group\n",
    "    df_normalized = training_data.groupby([\"sentence\", \"language\"], group_keys=True).apply(\n",
    "        normalize_group, include_groups=False\n",
    "    )\n",
    "    df_normalized.reset_index(inplace=True)\n",
    "    df_normalized.drop(columns=[\"level_2\"], inplace=True)\n",
    "\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80041901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>language</th>\n",
       "      <th>n</th>\n",
       "      <th>node</th>\n",
       "      <th>degree</th>\n",
       "      <th>closeness</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>katz</th>\n",
       "      <th>load</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>avg_neighbor_degree</th>\n",
       "      <th>community</th>\n",
       "      <th>is_leaf</th>\n",
       "      <th>is_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.730183</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.932971</td>\n",
       "      <td>0.990346</td>\n",
       "      <td>0.996388</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.908084</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.891309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.598665</td>\n",
       "      <td>0.174312</td>\n",
       "      <td>0.518343</td>\n",
       "      <td>0.547862</td>\n",
       "      <td>0.477072</td>\n",
       "      <td>0.174312</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042182</td>\n",
       "      <td>0.236520</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.976170</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.415764</td>\n",
       "      <td>0.703950</td>\n",
       "      <td>0.567473</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197474</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.356543</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.277926</td>\n",
       "      <td>0.417002</td>\n",
       "      <td>0.302740</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197475</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.061625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029047</td>\n",
       "      <td>0.103774</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197476</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.467346</td>\n",
       "      <td>0.842910</td>\n",
       "      <td>0.614483</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197477</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.304498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>0.335177</td>\n",
       "      <td>0.074379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197478</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.413016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.272827</td>\n",
       "      <td>0.035827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197479 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence language   n  node  degree  closeness  betweenness  pagerank  \\\n",
       "0              2   Arabic  21    10    1.00   0.730183     0.724771  0.932971   \n",
       "1              2   Arabic  21     8    1.00   0.908084     0.990826  0.891309   \n",
       "2              2   Arabic  21     5    0.50   0.598665     0.174312  0.518343   \n",
       "3              2   Arabic  21    13    0.00   0.356589     0.000000  0.042182   \n",
       "4              2   Arabic  21     6    0.50   0.976170     0.908257  0.415764   \n",
       "...          ...      ...  ..   ...     ...        ...          ...       ...   \n",
       "197474       995  Turkish  16    14    0.25   0.356543     0.200000  0.277926   \n",
       "197475       995  Turkish  16    10    0.00   0.061625     0.000000  0.029047   \n",
       "197476       995  Turkish  16     2    0.50   1.000000     0.885714  0.467346   \n",
       "197477       995  Turkish  16     1    0.00   0.304498     0.000000  0.007093   \n",
       "197478       995  Turkish  16    15    0.00   0.413016     0.000000  0.002320   \n",
       "\n",
       "        eigenvector      katz      load  eccentricity  avg_neighbor_degree  \\\n",
       "0          0.990346  0.996388  0.724771      0.571429             0.555556   \n",
       "1          1.000000  1.000000  0.990826      0.428571             0.555556   \n",
       "2          0.547862  0.477072  0.174312      0.571429             0.333333   \n",
       "3          0.236520  0.004953  0.000000      0.714286             0.333333   \n",
       "4          0.703950  0.567473  0.908257      0.285714             1.000000   \n",
       "...             ...       ...       ...           ...                  ...   \n",
       "197474     0.417002  0.302740  0.200000      0.666667             0.411765   \n",
       "197475     0.103774  0.004653  0.000000      1.000000             0.117647   \n",
       "197476     0.842910  0.614483  0.885714      0.000000             0.509804   \n",
       "197477     0.335177  0.074379  0.000000      0.666667             1.000000   \n",
       "197478     0.272827  0.035827  0.000000      0.333333             0.411765   \n",
       "\n",
       "        community  is_leaf  is_root  \n",
       "0        0.000000      0.0        1  \n",
       "1        0.666667      0.0        0  \n",
       "2        0.666667      0.0        0  \n",
       "3        0.666667      1.0        0  \n",
       "4        0.666667      0.0        0  \n",
       "...           ...      ...      ...  \n",
       "197474   0.000000      0.0        0  \n",
       "197475   0.000000      1.0        0  \n",
       "197476   0.666667      0.0        0  \n",
       "197477   0.000000      1.0        0  \n",
       "197478   0.666667      1.0        0  \n",
       "\n",
       "[197479 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pre_processing(df_train_raw)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e820604",
   "metadata": {},
   "source": [
    "# 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677bab87",
   "metadata": {},
   "source": [
    "**K-Fold Cross Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946279fa",
   "metadata": {},
   "source": [
    "Evaluate different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bebbde95",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_rf = [\n",
    "    {\"max_depth\": 10, \"min_samples_split\": 5, \"n_estimators\": 50, \"class_weight\": \"balanced\"},  # √°rbol m√°s peque√±o\n",
    "    {\"max_depth\": 20, \"min_samples_split\": 10, \"n_estimators\": 50, \"class_weight\": \"balanced\"}, # m√°s regularizado\n",
    "    {\"max_depth\": 20, \"min_samples_split\": 5, \"n_estimators\": 100, \"class_weight\": \"balanced\"}, # m√°s √°rboles\n",
    "    {\"max_depth\": None, \"min_samples_split\": 5, \"n_estimators\": 50, \"class_weight\": \"balanced\"}, # sin l√≠mite de profundidad\n",
    "]\n",
    "\n",
    "\n",
    "comparisons_dt = [\n",
    "    {\"max_depth\": 50, \"min_samples_split\": 5, \"class_weight\": \"balanced\"},   # m√°s limitado que el √≥ptimo\n",
    "    {\"max_depth\": None, \"min_samples_split\": 10, \"class_weight\": \"balanced\"}, # menos sobreajuste\n",
    "    {\"max_depth\": 20, \"min_samples_split\": 5, \"class_weight\": \"balanced\"},    # muy limitado\n",
    "]\n",
    "\n",
    "comparisons_logreg_large = [\n",
    "    {\"penalty\": \"l2\", \"C\": 0.1, \"solver\": \"saga\", \"class_weight\": \"balanced\", \"max_iter\": 1000, \"n_jobs\": -1},  # strong regularization\n",
    "    {\"penalty\": \"l2\", \"C\": 1.0, \"solver\": \"saga\", \"class_weight\": \"balanced\", \"max_iter\": 1000, \"n_jobs\": -1},  # default\n",
    "    {\"penalty\": \"l1\", \"C\": 1.0, \"solver\": \"saga\", \"class_weight\": \"balanced\", \"max_iter\": 1000, \"n_jobs\": -1},  # sparse features\n",
    "    {\"penalty\": \"elasticnet\", \"C\": 1.0, \"solver\": \"saga\", \"l1_ratio\": 0.5, \"class_weight\": \"balanced\", \"max_iter\": 1000, \"n_jobs\": -1},  # mix L1/L2\n",
    "    {\"penalty\": \"l2\", \"C\": 0.1, \"solver\": \"lbfgs\", \"class_weight\": \"balanced\"},   # stronger regularization\n",
    "    {\"penalty\": \"l2\", \"C\": 1.0, \"solver\": \"lbfgs\", \"class_weight\": \"balanced\"},   # default regularization\n",
    "    {\"penalty\": \"l2\", \"C\": 10.0, \"solver\": \"lbfgs\", \"class_weight\": \"balanced\"}\n",
    "]\n",
    "\n",
    "\n",
    "features = [col for col in df_train.columns if col not in ['id', 'sentence', 'language', 'is_root', 'group_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7b334",
   "metadata": {},
   "source": [
    "To check if it overfits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac8790",
   "metadata": {},
   "source": [
    "He visto que dentro de la funci√≥n de RandomForestClassifier, tu especificas un n_estimator = n, que te indica el n√∫mero de √°rboles de decisi√≥n que quieres tener en tu random forest. El problema viene que cuando el √°rbol coje los datos que le das, este no respeta el group_id, as√≠ que puede ser que nodos de la misma frase est√©n en diferentes √°rboles de decisi√≥n. Es por eso que he creado la classe de random forest des de cero, teniendo en cuenta este group id a la hora de hacer el bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4cc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Clase personalizada para Random Forest que respeta los grupos\n",
    "class GroupAwareRandomForest:\n",
    "    def __init__(self, n_estimators=50, max_depth=None, min_samples_split=2, class_weight=None, random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.class_weight = class_weight\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y, group_ids):\n",
    "        np.random.seed(self.random_state)\n",
    "        self.trees = []\n",
    "\n",
    "        unique_groups = np.unique(group_ids)\n",
    "        group_to_indices = defaultdict(list)\n",
    "        for idx, group in enumerate(group_ids):\n",
    "            group_to_indices[group].append(idx)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            sampled_groups = np.random.choice(unique_groups, size=int(0.8 * len(unique_groups)), replace=True)\n",
    "            sampled_indices = []\n",
    "            for group in sampled_groups:\n",
    "                sampled_indices.extend(group_to_indices[group])\n",
    "            sampled_indices = np.array(sampled_indices)\n",
    "\n",
    "            tree = DecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                class_weight=self.class_weight,\n",
    "                random_state=self.random_state\n",
    "            )\n",
    "            tree.fit(X.iloc[sampled_indices], y.iloc[sampled_indices])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = np.zeros((len(self.trees), len(X)))\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            preds[i] = tree.predict(X)\n",
    "        return (np.mean(preds, axis=0) > 0.5).astype(int)\n",
    "\n",
    "# Funci√≥n de evaluaci√≥n general\n",
    "def evaluate_models(df, features, comparisons_rf, comparisons_dt, comparisons_group_rf=None):\n",
    "    df['group_id'] = df[\"sentence\"].astype(str) + '_' + df[\"language\"]\n",
    "    X = df[features]\n",
    "    y = df['is_root']\n",
    "    groups = df[\"group_id\"]\n",
    "\n",
    "    results = []\n",
    "    cv = StratifiedGroupKFold(n_splits=10)\n",
    "\n",
    "    def evaluate_model(name, model, config, use_group_fit=False):\n",
    "        train_scores = []\n",
    "        val_scores = []\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X, y, groups):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            group_train = groups.iloc[train_idx]\n",
    "\n",
    "            if use_group_fit:\n",
    "                model.fit(X_train, y_train, group_train)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "\n",
    "            f1_train = f1_score(y_train, y_train_pred, average='weighted')\n",
    "            f1_val = f1_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "            train_scores.append(f1_train)\n",
    "            val_scores.append(f1_val)\n",
    "\n",
    "        avg_train = np.mean(train_scores)\n",
    "        avg_val = np.mean(val_scores)\n",
    "        std_train = np.std(train_scores)\n",
    "        std_val = np.std(val_scores)\n",
    "        avg_diff = np.mean(np.array(train_scores) - np.array(val_scores))\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Params\": config,\n",
    "            \"Train_F1_mean\": round(avg_train, 4),\n",
    "            \"Train_F1_std\": round(std_train, 4),\n",
    "            \"Val_F1_mean\": round(avg_val, 4),\n",
    "            \"Val_F1_std\": round(std_val, 4),\n",
    "            \"Gap_Train-Val\": round(avg_diff, 4)\n",
    "        })\n",
    "\n",
    "    # Random Forest est√°ndar\n",
    "    for cfg in comparisons_rf:\n",
    "        model = RandomForestClassifier(\n",
    "            max_depth=cfg[\"max_depth\"],\n",
    "            min_samples_split=cfg[\"min_samples_split\"],\n",
    "            n_estimators=cfg[\"n_estimators\"],\n",
    "            class_weight=cfg[\"class_weight\"],\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        evaluate_model(\"Random Forest\", model, cfg)\n",
    "\n",
    "    # Decision Tree est√°ndar\n",
    "    for cfg in comparisons_dt:\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=cfg[\"max_depth\"],\n",
    "            min_samples_split=cfg[\"min_samples_split\"],\n",
    "            class_weight=cfg[\"class_weight\"],\n",
    "            random_state=42\n",
    "        )\n",
    "        evaluate_model(\"Decision Tree\", model, cfg)\n",
    "\n",
    "    # Random Forest con respeto a group_id\n",
    "    if comparisons_group_rf is not None:\n",
    "        for cfg in comparisons_group_rf:\n",
    "            model = GroupAwareRandomForest(\n",
    "                n_estimators=cfg[\"n_estimators\"],\n",
    "                max_depth=cfg[\"max_depth\"],\n",
    "                min_samples_split=cfg[\"min_samples_split\"],\n",
    "                class_weight=cfg[\"class_weight\"],\n",
    "                random_state=42\n",
    "            )\n",
    "            evaluate_model(\"GroupAware Random Forest\", model, cfg, use_group_fit=True)\n",
    "    for lr in comparisons_logreg_large:\n",
    "        model = LogisticRegression(\n",
    "            penalty=lr[\"penalty\"],\n",
    "            solver=lr[\"solver\"],\n",
    "            C=lr[\"C\"],\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=1000\n",
    "        )\n",
    "        evaluate_model(\"Logistic Regression\", model, lr)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de2788b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomparisons_rf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomparisons_dt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomparisons_rf\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 109\u001b[0m, in \u001b[0;36mevaluate_models\u001b[0;34m(df, features, comparisons_rf, comparisons_dt, comparisons_group_rf)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cfg \u001b[38;5;129;01min\u001b[39;00m comparisons_rf:\n\u001b[1;32m    101\u001b[0m     model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[1;32m    102\u001b[0m         max_depth\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    103\u001b[0m         min_samples_split\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    108\u001b[0m     )\n\u001b[0;32m--> 109\u001b[0m     \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRandom Forest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Decision Tree est√°ndar\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cfg \u001b[38;5;129;01min\u001b[39;00m comparisons_dt:\n",
      "Cell \u001b[0;32mIn[8], line 72\u001b[0m, in \u001b[0;36mevaluate_models.<locals>.evaluate_model\u001b[0;34m(name, model, config, use_group_fit)\u001b[0m\n\u001b[1;32m     70\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, group_train)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[1;32m     75\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m~/Documents/MDS/2S/ProjectML/.venv/lib/python3.9/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MDS/2S/ProjectML/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    479\u001b[0m ]\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Documents/MDS/2S/ProjectML/.venv/lib/python3.9/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MDS/2S/ProjectML/.venv/lib/python3.9/site-packages/joblib/parallel.py:2071\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2065\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2071\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MDS/2S/ProjectML/.venv/lib/python3.9/site-packages/joblib/parallel.py:1681\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1681\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MDS/2S/ProjectML/.venv/lib/python3.9/site-packages/joblib/parallel.py:1799\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[1;32m   1789\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1794\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1798\u001b[0m     ):\n\u001b[0;32m-> 1799\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1800\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1803\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1810\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = evaluate_models(\n",
    "    df_train,\n",
    "    features,\n",
    "    comparisons_rf,\n",
    "    comparisons_dt,\n",
    "    comparisons_rf\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5596780",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).sort_values(by=\"Val_F1_mean\", ascending=False).to_csv(\"best_parameters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c3fbf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Params</th>\n",
       "      <th>Train_F1_mean</th>\n",
       "      <th>Train_F1_std</th>\n",
       "      <th>Val_F1_mean</th>\n",
       "      <th>Val_F1_std</th>\n",
       "      <th>Gap_Train-Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9323</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GroupAware Random Forest</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.9234</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GroupAware Random Forest</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GroupAware Random Forest</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 5, 'cla...</td>\n",
       "      <td>0.9810</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 10, '...</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.9046</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'cla...</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.8608</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GroupAware Random Forest</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  \\\n",
       "3              Random Forest   \n",
       "10  GroupAware Random Forest   \n",
       "2              Random Forest   \n",
       "1              Random Forest   \n",
       "9   GroupAware Random Forest   \n",
       "8   GroupAware Random Forest   \n",
       "4              Decision Tree   \n",
       "5              Decision Tree   \n",
       "6              Decision Tree   \n",
       "0              Random Forest   \n",
       "7   GroupAware Random Forest   \n",
       "\n",
       "                                               Params  Train_F1_mean  \\\n",
       "3   {'max_depth': None, 'min_samples_split': 5, 'n...         0.9901   \n",
       "10  {'max_depth': None, 'min_samples_split': 5, 'n...         0.9892   \n",
       "2   {'max_depth': 20, 'min_samples_split': 5, 'n_e...         0.9576   \n",
       "1   {'max_depth': 20, 'min_samples_split': 10, 'n_...         0.9524   \n",
       "9   {'max_depth': 20, 'min_samples_split': 5, 'n_e...         0.9512   \n",
       "8   {'max_depth': 20, 'min_samples_split': 10, 'n_...         0.9483   \n",
       "4   {'max_depth': 50, 'min_samples_split': 5, 'cla...         0.9810   \n",
       "5   {'max_depth': None, 'min_samples_split': 10, '...         0.9601   \n",
       "6   {'max_depth': 20, 'min_samples_split': 5, 'cla...         0.9226   \n",
       "0   {'max_depth': 10, 'min_samples_split': 5, 'n_e...         0.8666   \n",
       "7   {'max_depth': 10, 'min_samples_split': 5, 'n_e...         0.8564   \n",
       "\n",
       "    Train_F1_std  Val_F1_mean  Val_F1_std  Gap_Train-Val  \n",
       "3         0.0002       0.9323      0.0011         0.0577  \n",
       "10        0.0002       0.9311      0.0008         0.0581  \n",
       "2         0.0008       0.9234      0.0016         0.0341  \n",
       "1         0.0007       0.9216      0.0016         0.0307  \n",
       "9         0.0008       0.9205      0.0012         0.0307  \n",
       "8         0.0009       0.9191      0.0015         0.0291  \n",
       "4         0.0002       0.9141      0.0018         0.0669  \n",
       "5         0.0003       0.9046      0.0018         0.0555  \n",
       "6         0.0024       0.8877      0.0024         0.0349  \n",
       "0         0.0010       0.8608      0.0023         0.0059  \n",
       "7         0.0023       0.8514      0.0024         0.0050  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).sort_values(by=\"Val_F1_mean\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdfbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
