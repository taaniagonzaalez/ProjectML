{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324e8a16",
   "metadata": {},
   "source": [
    "# üêç Machine Learning Project Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183be9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd12ce1",
   "metadata": {},
   "source": [
    "# 1. Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d76f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_csv(\"train.csv\", sep=',')\n",
    "df_train_raw[\"edgelist\"].head(1)\n",
    "df_train_raw[\"edgelist\"] = df_train_raw[\"edgelist\"].apply(ast.literal_eval)\n",
    "\n",
    "df_test_raw = pd.read_csv(\"test.csv\", sep=',')\n",
    "df_test_raw[\"edgelist\"].head(1)\n",
    "df_test_raw[\"edgelist\"] = df_test_raw[\"edgelist\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536ab68",
   "metadata": {},
   "source": [
    "# 2. Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4dd84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from community import community_louvain  # pip install python-louvain\n",
    "\n",
    "def normalize_group(df_group):\n",
    "    numeric_cols = [\n",
    "        'degree', 'closeness', 'betweenness', 'pagerank',\n",
    "        'eigenvector', 'katz', 'load',\n",
    "        'eccentricity', 'avg_neighbor_degree',\n",
    "         'community', 'is_leaf'\n",
    "        #'shortest_path_length', 'is_leaf', 'neighbor_connectivity'\n",
    "    ]\n",
    "    scaler = MinMaxScaler()\n",
    "    df_group[numeric_cols] = scaler.fit_transform(df_group[numeric_cols])\n",
    "    return df_group\n",
    "\n",
    "def pre_processing(data):\n",
    "    training_data = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        edgelist = row[\"edgelist\"]\n",
    "        \n",
    "        # Create undirected graph\n",
    "        T = nx.Graph()\n",
    "        T.add_edges_from(edgelist)\n",
    "\n",
    "        if not nx.is_connected(T):\n",
    "            continue\n",
    "        \n",
    "        root_node = row.get(\"root\", None)\n",
    "        \n",
    "        # Compute centralities\n",
    "        closeness = nx.closeness_centrality(T)\n",
    "        betweenness = nx.betweenness_centrality(T)\n",
    "        pagerank = nx.pagerank(T, max_iter=1000)\n",
    "        \n",
    "        # Additional centrality measures with fallbacks\n",
    "        try:\n",
    "            eigenvector = nx.eigenvector_centrality(T, max_iter=10000, tol=1e-06)\n",
    "        except nx.PowerIterationFailedConvergence:\n",
    "            eigenvector = {n: 0.0 for n in T.nodes}\n",
    "            \n",
    "        try:\n",
    "            katz = nx.katz_centrality(T, alpha=0.1)\n",
    "        except nx.NetworkXException:\n",
    "            katz = {n: 0.0 for n in T.nodes}\n",
    "            \n",
    "        try:\n",
    "            load = nx.load_centrality(T)\n",
    "        except:\n",
    "            load = {n: 0.0 for n in T.nodes}\n",
    "\n",
    "        # Structural properties\n",
    "        degree = dict(T.degree())\n",
    "        eccentricity = nx.eccentricity(T)\n",
    "        avg_neighbor_degree = nx.average_neighbor_degree(T)\n",
    "        \n",
    "        # Community detection\n",
    "        partition = community_louvain.best_partition(T)\n",
    "        \n",
    "        for v in T.nodes:\n",
    "            features = {\n",
    "                \"sentence\": row[\"sentence\"],\n",
    "                \"language\": row[\"language\"],\n",
    "                \"n\": row[\"n\"],\n",
    "                \"node\": v,\n",
    "\n",
    "                # Centrality measures\n",
    "                \"degree\": degree[v],\n",
    "                \"closeness\": closeness[v],\n",
    "                \"betweenness\": betweenness[v],\n",
    "                \"pagerank\": pagerank[v],\n",
    "                \"eigenvector\": eigenvector[v],\n",
    "                \"katz\": katz[v],\n",
    "                \"load\": load[v],\n",
    "\n",
    "                # Structural properties\n",
    "                \"eccentricity\": eccentricity[v],\n",
    "                \"avg_neighbor_degree\": avg_neighbor_degree[v],\n",
    "\n",
    "                # Community information\n",
    "                \"community\": partition[v],\n",
    "\n",
    "                \"is_leaf\": 1 if T.degree(v) == 1 else 0,\n",
    "            }\n",
    "\n",
    "            if \"id\" in row:\n",
    "                features[\"id\"] = row[\"id\"]\n",
    "\n",
    "            if root_node is not None:\n",
    "                features[\"is_root\"] = 1 if v == root_node else 0\n",
    "\n",
    "            training_data.append(features)\n",
    "\n",
    "    training_data = pd.DataFrame(training_data)\n",
    "    \n",
    "    # Normalize features by group\n",
    "    df_normalized = training_data.groupby([\"sentence\", \"language\"], group_keys=True).apply(\n",
    "        normalize_group, include_groups=False\n",
    "    )\n",
    "    df_normalized.reset_index(inplace=True)\n",
    "    df_normalized.drop(columns=[\"level_2\"], inplace=True)\n",
    "\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80041901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>language</th>\n",
       "      <th>n</th>\n",
       "      <th>node</th>\n",
       "      <th>degree</th>\n",
       "      <th>closeness</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>katz</th>\n",
       "      <th>load</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>avg_neighbor_degree</th>\n",
       "      <th>community</th>\n",
       "      <th>is_leaf</th>\n",
       "      <th>is_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.730183</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.932971</td>\n",
       "      <td>0.990346</td>\n",
       "      <td>0.996388</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.908084</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.891309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.598665</td>\n",
       "      <td>0.174312</td>\n",
       "      <td>0.518343</td>\n",
       "      <td>0.547862</td>\n",
       "      <td>0.477072</td>\n",
       "      <td>0.174312</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042182</td>\n",
       "      <td>0.236520</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.976170</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.415764</td>\n",
       "      <td>0.703950</td>\n",
       "      <td>0.567473</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197474</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.356543</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.277926</td>\n",
       "      <td>0.417002</td>\n",
       "      <td>0.302740</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197475</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.061625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029047</td>\n",
       "      <td>0.103774</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197476</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.467346</td>\n",
       "      <td>0.842910</td>\n",
       "      <td>0.614483</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197477</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.304498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>0.335177</td>\n",
       "      <td>0.074379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197478</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.413016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.272827</td>\n",
       "      <td>0.035827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197479 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence language   n  node  degree  closeness  betweenness  pagerank  \\\n",
       "0              2   Arabic  21    10    1.00   0.730183     0.724771  0.932971   \n",
       "1              2   Arabic  21     8    1.00   0.908084     0.990826  0.891309   \n",
       "2              2   Arabic  21     5    0.50   0.598665     0.174312  0.518343   \n",
       "3              2   Arabic  21    13    0.00   0.356589     0.000000  0.042182   \n",
       "4              2   Arabic  21     6    0.50   0.976170     0.908257  0.415764   \n",
       "...          ...      ...  ..   ...     ...        ...          ...       ...   \n",
       "197474       995  Turkish  16    14    0.25   0.356543     0.200000  0.277926   \n",
       "197475       995  Turkish  16    10    0.00   0.061625     0.000000  0.029047   \n",
       "197476       995  Turkish  16     2    0.50   1.000000     0.885714  0.467346   \n",
       "197477       995  Turkish  16     1    0.00   0.304498     0.000000  0.007093   \n",
       "197478       995  Turkish  16    15    0.00   0.413016     0.000000  0.002320   \n",
       "\n",
       "        eigenvector      katz      load  eccentricity  avg_neighbor_degree  \\\n",
       "0          0.990346  0.996388  0.724771      0.571429             0.555556   \n",
       "1          1.000000  1.000000  0.990826      0.428571             0.555556   \n",
       "2          0.547862  0.477072  0.174312      0.571429             0.333333   \n",
       "3          0.236520  0.004953  0.000000      0.714286             0.333333   \n",
       "4          0.703950  0.567473  0.908257      0.285714             1.000000   \n",
       "...             ...       ...       ...           ...                  ...   \n",
       "197474     0.417002  0.302740  0.200000      0.666667             0.411765   \n",
       "197475     0.103774  0.004653  0.000000      1.000000             0.117647   \n",
       "197476     0.842910  0.614483  0.885714      0.000000             0.509804   \n",
       "197477     0.335177  0.074379  0.000000      0.666667             1.000000   \n",
       "197478     0.272827  0.035827  0.000000      0.333333             0.411765   \n",
       "\n",
       "        community  is_leaf  is_root  \n",
       "0        0.000000      0.0        1  \n",
       "1        0.666667      0.0        0  \n",
       "2        0.666667      0.0        0  \n",
       "3        0.666667      1.0        0  \n",
       "4        0.666667      0.0        0  \n",
       "...           ...      ...      ...  \n",
       "197474   0.666667      0.0        0  \n",
       "197475   0.666667      1.0        0  \n",
       "197476   0.000000      0.0        0  \n",
       "197477   0.666667      1.0        0  \n",
       "197478   0.000000      1.0        0  \n",
       "\n",
       "[197479 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pre_processing(df_train_raw)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e820604",
   "metadata": {},
   "source": [
    "# 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677bab87",
   "metadata": {},
   "source": [
    "**K-Fold Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678963a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def f1_weighted(y_true, y_pred):\n",
    "    from sklearn.metrics import classification_report\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return report['weighted avg']['f1-score']\n",
    "\n",
    "def grid_search_models(df, features, n_folds=5):\n",
    "    \"\"\"\n",
    "    Perform grid search on three models and return best parameters for each.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the data\n",
    "        features: List of feature columns to use\n",
    "        n_folds: Number of cross-validation folds\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with model names as keys and their best parameters as values\n",
    "    \"\"\"\n",
    "    df['group_id'] = df[\"sentence\"].astype(str) + '_' + df[\"language\"]\n",
    "    X = df[features]\n",
    "    y = df['is_root']\n",
    "    groups = df[\"group_id\"]\n",
    "    \n",
    "    # Define parameter grids for each model\n",
    "    param_grids = {\n",
    "        \"Random Forest\": {\n",
    "            'classifier__max_depth': [10, 20, 30],\n",
    "            'classifier__min_samples_split': [5, 10, 15],\n",
    "            'classifier__min_samples_leaf': [2, 5, 10],\n",
    "            'classifier__n_estimators': [50, 100],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        },\n",
    "        \"Decision Tree\": {\n",
    "            'classifier__max_depth': [50, 100, None],\n",
    "            'classifier__min_samples_split': [5, 10, 20],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "        # \"XGB Classifier\": {\n",
    "        #     'classifier__max_depth': [3, 4, 5],\n",
    "        #     'classifier__learning_rate': [0.01, 0.1],\n",
    "        #     'classifier__subsample': [0.7, 0.8],\n",
    "        #     'classifier__n_estimators': [50, 100],\n",
    "        #     'classifier__reg_alpha': [0, 0.5],\n",
    "        #     'classifier__reg_lambda': [0.5, 1]\n",
    "        # }\n",
    "    }\n",
    "    \n",
    "    # Base models\n",
    "    base_models = {\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42)\n",
    "        # \"XGB Classifier\": XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "    }\n",
    "    \n",
    "    best_params = {}\n",
    "    scorer = make_scorer(f1_weighted, greater_is_better=True)\n",
    "\n",
    "    for model_name, model in base_models.items():\n",
    "        print(f\"\\n=== Grid Search for {model_name} ===\")\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('feature_selector', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        # Custom CV that preserves groups\n",
    "        cv = StratifiedGroupKFold(n_splits=n_folds)\n",
    "        \n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grids[model_name],\n",
    "            cv=cv,\n",
    "            scoring=scorer,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Fit grid search\n",
    "        grid_search.fit(X, y, groups=groups)\n",
    "        \n",
    "        # Store best parameters\n",
    "        best_params[model_name] = grid_search.best_params_\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "# Example usage:\n",
    "# best_params = grid_search_models(df, features)\n",
    "# print(\"\\nBest parameters for all models:\")\n",
    "# for model, params in best_params.items():\n",
    "#     print(f\"{model}: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ad267",
   "metadata": {},
   "source": [
    "Grid Search optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df240e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def f1_weighted(y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return report['weighted avg']['f1-score']\n",
    "\n",
    "def grid_search_models(df, features, n_folds=5):\n",
    "    \"\"\"\n",
    "    Fast grid search for Random Forest and Decision Tree on large datasets.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with the dataset\n",
    "        features: List of feature column names\n",
    "        n_folds: Number of folds for cross-validation\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with best parameters for each model\n",
    "    \"\"\"\n",
    "    df['group_id'] = df[\"sentence\"].astype(str) + '_' + df[\"language\"]\n",
    "    X = df[features]\n",
    "    y = df['is_root']\n",
    "    groups = df[\"group_id\"]\n",
    "\n",
    "    # Simplified hyperparameter grids\n",
    "    param_grids = {\n",
    "        \"Random Forest\": {\n",
    "            'classifier__max_depth': [10, 20],\n",
    "            'classifier__min_samples_split': [5, 10],\n",
    "            'classifier__n_estimators': [50],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        },\n",
    "        \"Decision Tree\": {\n",
    "            'classifier__max_depth': [50, None],\n",
    "            'classifier__min_samples_split': [5, 10],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Base models\n",
    "    base_models = {\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42)\n",
    "    }\n",
    "\n",
    "    best_params = {}\n",
    "    scorer = make_scorer(f1_weighted, greater_is_better=True)\n",
    "\n",
    "    for model_name, model in base_models.items():\n",
    "        print(f\"\\n=== Grid Search for {model_name} ===\")\n",
    "\n",
    "        # Pipeline (sin SelectFromModel para acelerar)\n",
    "        pipeline = Pipeline([\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "        cv = StratifiedGroupKFold(n_splits=n_folds)\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grids[model_name],\n",
    "            cv=cv,\n",
    "            scoring=scorer,\n",
    "            n_jobs=-1,  # Usa todos los n√∫cleos disponibles\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X, y, groups=groups)\n",
    "\n",
    "        best_params[model_name] = grid_search.best_params_\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51fd11af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grid Search for Random Forest ===\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters: {'classifier__class_weight': 'balanced', 'classifier__max_depth': 20, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 50}\n",
      "\n",
      "=== Grid Search for Decision Tree ===\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters: {'classifier__class_weight': 'balanced', 'classifier__max_depth': None, 'classifier__min_samples_split': 5}\n",
      "\n",
      "Best parameters for all models:\n",
      "Random Forest: {'classifier__class_weight': 'balanced', 'classifier__max_depth': 20, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 50}\n",
      "Decision Tree: {'classifier__class_weight': 'balanced', 'classifier__max_depth': None, 'classifier__min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "# === Run pipeline ===\n",
    "\n",
    "features = [col for col in df_train.columns if col not in ['id', 'sentence', 'language', 'is_root', 'group_id']]\n",
    "\n",
    "best_params = grid_search_models(df_train, features)\n",
    "\n",
    "print(\"\\nBest parameters for all models:\")\n",
    "for model, params in best_params.items():\n",
    "     print(f\"{model}: {params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946279fa",
   "metadata": {},
   "source": [
    "Evaluate different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebbde95",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_rf = [\n",
    "    {\"max_depth\": 10, \"min_samples_split\": 5, \"n_estimators\": 50, \"class_weight\": \"balanced\"},  # √°rbol m√°s peque√±o\n",
    "    {\"max_depth\": 20, \"min_samples_split\": 10, \"n_estimators\": 50, \"class_weight\": \"balanced\"}, # m√°s regularizado\n",
    "    {\"max_depth\": 20, \"min_samples_split\": 5, \"n_estimators\": 100, \"class_weight\": \"balanced\"}, # m√°s √°rboles\n",
    "    {\"max_depth\": None, \"min_samples_split\": 5, \"n_estimators\": 50, \"class_weight\": \"balanced\"}, # sin l√≠mite de profundidad\n",
    "]\n",
    "\n",
    "\n",
    "comparisons_dt = [\n",
    "    {\"max_depth\": 50, \"min_samples_split\": 5, \"class_weight\": \"balanced\"},   # m√°s limitado que el √≥ptimo\n",
    "    {\"max_depth\": None, \"min_samples_split\": 10, \"class_weight\": \"balanced\"}, # menos sobreajuste\n",
    "    {\"max_depth\": 20, \"min_samples_split\": 5, \"class_weight\": \"balanced\"},    # muy limitado\n",
    "]\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def evaluate_models(df, features, comparisons_rf, comparisons_dt):\n",
    "    df['group_id'] = df[\"sentence\"].astype(str) + '_' + df[\"language\"]\n",
    "    X = df[features]\n",
    "    y = df['is_root']\n",
    "    groups = df[\"group_id\"]\n",
    "\n",
    "    results = []\n",
    "    cv = StratifiedGroupKFold(n_splits=10)\n",
    "\n",
    "    def evaluate_model(name, model, config):\n",
    "        f1s = []\n",
    "        for train_idx, test_idx in cv.split(X, y, groups):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            f1 = report['weighted avg']['f1-score']\n",
    "            f1s.append(f1)\n",
    "\n",
    "        avg_f1 = sum(f1s) / len(f1s)\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Params\": config,\n",
    "            \"F1_score\": round(avg_f1, 4)\n",
    "        })\n",
    "\n",
    "    # Evaluate Random Forest configs\n",
    "    for cfg in comparisons_rf:\n",
    "        model = RandomForestClassifier(\n",
    "            max_depth=cfg[\"max_depth\"],\n",
    "            min_samples_split=cfg[\"min_samples_split\"],\n",
    "            n_estimators=cfg[\"n_estimators\"],\n",
    "            class_weight=cfg[\"class_weight\"],\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        evaluate_model(\"Random Forest\", model, cfg)\n",
    "\n",
    "    # Evaluate Decision Tree configs\n",
    "    for cfg in comparisons_dt:\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=cfg[\"max_depth\"],\n",
    "            min_samples_split=cfg[\"min_samples_split\"],\n",
    "            class_weight=cfg[\"class_weight\"],\n",
    "            random_state=42\n",
    "        )\n",
    "        evaluate_model(\"Decision Tree\", model, cfg)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d31892b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Params</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>0.9323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>0.9234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>0.9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 5, 'cla...</td>\n",
       "      <td>0.9141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 10, '...</td>\n",
       "      <td>0.9046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'cla...</td>\n",
       "      <td>0.8877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>0.8608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model                                             Params  F1_score\n",
       "3  Random Forest  {'max_depth': None, 'min_samples_split': 5, 'n...    0.9323\n",
       "2  Random Forest  {'max_depth': 20, 'min_samples_split': 5, 'n_e...    0.9234\n",
       "1  Random Forest  {'max_depth': 20, 'min_samples_split': 10, 'n_...    0.9216\n",
       "4  Decision Tree  {'max_depth': 50, 'min_samples_split': 5, 'cla...    0.9141\n",
       "5  Decision Tree  {'max_depth': None, 'min_samples_split': 10, '...    0.9046\n",
       "6  Decision Tree  {'max_depth': 20, 'min_samples_split': 5, 'cla...    0.8877\n",
       "0  Random Forest  {'max_depth': 10, 'min_samples_split': 5, 'n_e...    0.8608"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluate_models(df_train, features, comparisons_rf, comparisons_dt)\n",
    "import pandas as pd\n",
    "pd.DataFrame(results).sort_values(by=\"F1_score\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7b334",
   "metadata": {},
   "source": [
    "To check if it overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e3439fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_models(df, features, comparisons_rf, comparisons_dt):\n",
    "    df['group_id'] = df[\"sentence\"].astype(str) + '_' + df[\"language\"]\n",
    "    X = df[features]\n",
    "    y = df['is_root']\n",
    "    groups = df[\"group_id\"]\n",
    "\n",
    "    results = []\n",
    "    cv = StratifiedGroupKFold(n_splits=10)\n",
    "\n",
    "    def evaluate_model(name, model, config):\n",
    "        train_scores = []\n",
    "        val_scores = []\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X, y, groups):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "\n",
    "            f1_train = f1_score(y_train, y_train_pred, average='weighted')\n",
    "            f1_val = f1_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "            train_scores.append(f1_train)\n",
    "            val_scores.append(f1_val)\n",
    "\n",
    "        avg_train = np.mean(train_scores)\n",
    "        avg_val = np.mean(val_scores)\n",
    "        std_train = np.std(train_scores)\n",
    "        std_val = np.std(val_scores)\n",
    "        avg_diff = np.mean(np.array(train_scores) - np.array(val_scores))\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Params\": config,\n",
    "            \"Train_F1_mean\": round(avg_train, 4),\n",
    "            \"Train_F1_std\": round(std_train, 4),\n",
    "            \"Val_F1_mean\": round(avg_val, 4),\n",
    "            \"Val_F1_std\": round(std_val, 4),\n",
    "            \"Gap_Train-Val\": round(avg_diff, 4)\n",
    "        })\n",
    "\n",
    "    # Evaluate Random Forest configs\n",
    "    for cfg in comparisons_rf:\n",
    "        model = RandomForestClassifier(\n",
    "            max_depth=cfg[\"max_depth\"],\n",
    "            min_samples_split=cfg[\"min_samples_split\"],\n",
    "            n_estimators=cfg[\"n_estimators\"],\n",
    "            class_weight=cfg[\"class_weight\"],\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        evaluate_model(\"Random Forest\", model, cfg)\n",
    "\n",
    "    # Evaluate Decision Tree configs\n",
    "    for cfg in comparisons_dt:\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=cfg[\"max_depth\"],\n",
    "            min_samples_split=cfg[\"min_samples_split\"],\n",
    "            class_weight=cfg[\"class_weight\"],\n",
    "            random_state=42\n",
    "        )\n",
    "        evaluate_model(\"Decision Tree\", model, cfg)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7439889b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'F1_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gx/8_x0j9wx7kl8gs36bydwh7l00000gr/T/ipykernel_5802/233751947.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomparisons_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomparisons_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"F1_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ProjectML/.venv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7185\u001b[0m             )\n\u001b[1;32m   7186\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7187\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7189\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7191\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ProjectML/.venv/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'F1_score'"
     ]
    }
   ],
   "source": [
    "results = evaluate_models(df_train, features, comparisons_rf, comparisons_dt)\n",
    "import pandas as pd\n",
    "pd.DataFrame(results).sort_values(by=\"Val_F1_mean\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4cc696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
