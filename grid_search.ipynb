{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324e8a16",
   "metadata": {},
   "source": [
    "# üêç Machine Learning Project Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183be9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd12ce1",
   "metadata": {},
   "source": [
    "# 1. Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d76f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_csv(\"train.csv\", sep=',')\n",
    "df_train_raw[\"edgelist\"].head(1)\n",
    "df_train_raw[\"edgelist\"] = df_train_raw[\"edgelist\"].apply(ast.literal_eval)\n",
    "\n",
    "df_test_raw = pd.read_csv(\"test.csv\", sep=',')\n",
    "df_test_raw[\"edgelist\"].head(1)\n",
    "df_test_raw[\"edgelist\"] = df_test_raw[\"edgelist\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536ab68",
   "metadata": {},
   "source": [
    "# 2. Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4dd84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from community import community_louvain  # pip install python-louvain\n",
    "\n",
    "def normalize_group(df_group):\n",
    "    numeric_cols = [\n",
    "        'degree', 'closeness', 'betweenness', 'pagerank',\n",
    "        'eigenvector', 'katz', 'load',\n",
    "        'eccentricity', 'avg_neighbor_degree',\n",
    "         'community', 'is_leaf'\n",
    "        #'shortest_path_length', 'is_leaf', 'neighbor_connectivity'\n",
    "    ]\n",
    "    scaler = MinMaxScaler()\n",
    "    df_group[numeric_cols] = scaler.fit_transform(df_group[numeric_cols])\n",
    "    return df_group\n",
    "\n",
    "def pre_processing(data):\n",
    "    training_data = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        edgelist = row[\"edgelist\"]\n",
    "        \n",
    "        # Create undirected graph\n",
    "        T = nx.Graph()\n",
    "        T.add_edges_from(edgelist)\n",
    "\n",
    "        if not nx.is_connected(T):\n",
    "            continue\n",
    "        \n",
    "        root_node = row.get(\"root\", None)\n",
    "        \n",
    "        # Compute centralities\n",
    "        closeness = nx.closeness_centrality(T)\n",
    "        betweenness = nx.betweenness_centrality(T)\n",
    "        pagerank = nx.pagerank(T, max_iter=1000)\n",
    "        \n",
    "        # Additional centrality measures with fallbacks\n",
    "        try:\n",
    "            eigenvector = nx.eigenvector_centrality(T, max_iter=10000, tol=1e-06)\n",
    "        except nx.PowerIterationFailedConvergence:\n",
    "            eigenvector = {n: 0.0 for n in T.nodes}\n",
    "            \n",
    "        try:\n",
    "            katz = nx.katz_centrality(T, alpha=0.1)\n",
    "        except nx.NetworkXException:\n",
    "            katz = {n: 0.0 for n in T.nodes}\n",
    "            \n",
    "        try:\n",
    "            load = nx.load_centrality(T)\n",
    "        except:\n",
    "            load = {n: 0.0 for n in T.nodes}\n",
    "\n",
    "        # Structural properties\n",
    "        degree = dict(T.degree())\n",
    "        eccentricity = nx.eccentricity(T)\n",
    "        avg_neighbor_degree = nx.average_neighbor_degree(T)\n",
    "        \n",
    "        # Community detection\n",
    "        partition = community_louvain.best_partition(T)\n",
    "        \n",
    "        for v in T.nodes:\n",
    "            features = {\n",
    "                \"sentence\": row[\"sentence\"],\n",
    "                \"language\": row[\"language\"],\n",
    "                \"n\": row[\"n\"],\n",
    "                \"node\": v,\n",
    "\n",
    "                # Centrality measures\n",
    "                \"degree\": degree[v],\n",
    "                \"closeness\": closeness[v],\n",
    "                \"betweenness\": betweenness[v],\n",
    "                \"pagerank\": pagerank[v],\n",
    "                \"eigenvector\": eigenvector[v],\n",
    "                \"katz\": katz[v],\n",
    "                \"load\": load[v],\n",
    "\n",
    "                # Structural properties\n",
    "                \"eccentricity\": eccentricity[v],\n",
    "                \"avg_neighbor_degree\": avg_neighbor_degree[v],\n",
    "\n",
    "                # Community information\n",
    "                \"community\": partition[v],\n",
    "\n",
    "                \"is_leaf\": 1 if T.degree(v) == 1 else 0,\n",
    "            }\n",
    "\n",
    "            if \"id\" in row:\n",
    "                features[\"id\"] = row[\"id\"]\n",
    "\n",
    "            if root_node is not None:\n",
    "                features[\"is_root\"] = 1 if v == root_node else 0\n",
    "\n",
    "            training_data.append(features)\n",
    "\n",
    "    training_data = pd.DataFrame(training_data)\n",
    "    \n",
    "    # Normalize features by group\n",
    "    df_normalized = training_data.groupby([\"sentence\", \"language\"], group_keys=True).apply(\n",
    "        normalize_group, include_groups=False\n",
    "    )\n",
    "    df_normalized.reset_index(inplace=True)\n",
    "    df_normalized.drop(columns=[\"level_2\"], inplace=True)\n",
    "\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80041901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>language</th>\n",
       "      <th>n</th>\n",
       "      <th>node</th>\n",
       "      <th>degree</th>\n",
       "      <th>closeness</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>katz</th>\n",
       "      <th>load</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>avg_neighbor_degree</th>\n",
       "      <th>community</th>\n",
       "      <th>is_leaf</th>\n",
       "      <th>is_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.730183</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.932971</td>\n",
       "      <td>0.990346</td>\n",
       "      <td>0.996388</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.908084</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.891309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.598665</td>\n",
       "      <td>0.174312</td>\n",
       "      <td>0.518343</td>\n",
       "      <td>0.547862</td>\n",
       "      <td>0.477072</td>\n",
       "      <td>0.174312</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042182</td>\n",
       "      <td>0.236520</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.976170</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.415764</td>\n",
       "      <td>0.703950</td>\n",
       "      <td>0.567473</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197474</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.356543</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.277926</td>\n",
       "      <td>0.417002</td>\n",
       "      <td>0.302740</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197475</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.061625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029047</td>\n",
       "      <td>0.103774</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197476</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.467346</td>\n",
       "      <td>0.842910</td>\n",
       "      <td>0.614483</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197477</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.304498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>0.335177</td>\n",
       "      <td>0.074379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197478</th>\n",
       "      <td>995</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.413016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.272827</td>\n",
       "      <td>0.035827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197479 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence language   n  node  degree  closeness  betweenness  pagerank  \\\n",
       "0              2   Arabic  21    10    1.00   0.730183     0.724771  0.932971   \n",
       "1              2   Arabic  21     8    1.00   0.908084     0.990826  0.891309   \n",
       "2              2   Arabic  21     5    0.50   0.598665     0.174312  0.518343   \n",
       "3              2   Arabic  21    13    0.00   0.356589     0.000000  0.042182   \n",
       "4              2   Arabic  21     6    0.50   0.976170     0.908257  0.415764   \n",
       "...          ...      ...  ..   ...     ...        ...          ...       ...   \n",
       "197474       995  Turkish  16    14    0.25   0.356543     0.200000  0.277926   \n",
       "197475       995  Turkish  16    10    0.00   0.061625     0.000000  0.029047   \n",
       "197476       995  Turkish  16     2    0.50   1.000000     0.885714  0.467346   \n",
       "197477       995  Turkish  16     1    0.00   0.304498     0.000000  0.007093   \n",
       "197478       995  Turkish  16    15    0.00   0.413016     0.000000  0.002320   \n",
       "\n",
       "        eigenvector      katz      load  eccentricity  avg_neighbor_degree  \\\n",
       "0          0.990346  0.996388  0.724771      0.571429             0.555556   \n",
       "1          1.000000  1.000000  0.990826      0.428571             0.555556   \n",
       "2          0.547862  0.477072  0.174312      0.571429             0.333333   \n",
       "3          0.236520  0.004953  0.000000      0.714286             0.333333   \n",
       "4          0.703950  0.567473  0.908257      0.285714             1.000000   \n",
       "...             ...       ...       ...           ...                  ...   \n",
       "197474     0.417002  0.302740  0.200000      0.666667             0.411765   \n",
       "197475     0.103774  0.004653  0.000000      1.000000             0.117647   \n",
       "197476     0.842910  0.614483  0.885714      0.000000             0.509804   \n",
       "197477     0.335177  0.074379  0.000000      0.666667             1.000000   \n",
       "197478     0.272827  0.035827  0.000000      0.333333             0.411765   \n",
       "\n",
       "        community  is_leaf  is_root  \n",
       "0        0.000000      0.0        1  \n",
       "1        0.333333      0.0        0  \n",
       "2        0.333333      0.0        0  \n",
       "3        0.333333      1.0        0  \n",
       "4        0.333333      0.0        0  \n",
       "...           ...      ...      ...  \n",
       "197474   0.666667      0.0        0  \n",
       "197475   0.666667      1.0        0  \n",
       "197476   0.000000      0.0        0  \n",
       "197477   0.666667      1.0        0  \n",
       "197478   0.000000      1.0        0  \n",
       "\n",
       "[197479 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pre_processing(df_train_raw)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e820604",
   "metadata": {},
   "source": [
    "# 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677bab87",
   "metadata": {},
   "source": [
    "**K-Fold Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "678963a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def f1_weighted(y_true, y_pred):\n",
    "    from sklearn.metrics import classification_report\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return report['weighted avg']['f1-score']\n",
    "\n",
    "def grid_search_models(df, features, n_folds=5):\n",
    "    \"\"\"\n",
    "    Perform grid search on three models and return best parameters for each.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the data\n",
    "        features: List of feature columns to use\n",
    "        n_folds: Number of cross-validation folds\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with model names as keys and their best parameters as values\n",
    "    \"\"\"\n",
    "    df['group_id'] = df[\"sentence\"].astype(str) + '_' + df[\"language\"]\n",
    "    X = df[features]\n",
    "    y = df['is_root']\n",
    "    groups = df[\"group_id\"]\n",
    "    \n",
    "    # Define parameter grids for each model\n",
    "    param_grids = {\n",
    "        \"Random Forest\": {\n",
    "            'classifier__max_depth': [10, 20, 30],\n",
    "            'classifier__min_samples_split': [5, 10, 15],\n",
    "            'classifier__min_samples_leaf': [2, 5, 10],\n",
    "            'classifier__n_estimators': [50, 100],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        },\n",
    "        \"Decision Tree\": {\n",
    "            'classifier__max_depth': [50, 100, None],\n",
    "            'classifier__min_samples_split': [5, 10, 20],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        },\n",
    "        \"XGB Classifier\": {\n",
    "            'classifier__max_depth': [3, 4, 5],\n",
    "            'classifier__learning_rate': [0.01, 0.1],\n",
    "            'classifier__subsample': [0.7, 0.8],\n",
    "            'classifier__n_estimators': [50, 100],\n",
    "            'classifier__reg_alpha': [0, 0.5],\n",
    "            'classifier__reg_lambda': [0.5, 1]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Base models\n",
    "    base_models = {\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"XGB Classifier\": XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "    }\n",
    "    \n",
    "    best_params = {}\n",
    "    scorer = make_scorer(f1_weighted, greater_is_better=True)\n",
    "\n",
    "    for model_name, model in base_models.items():\n",
    "        print(f\"\\n=== Grid Search for {model_name} ===\")\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('feature_selector', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        # Custom CV that preserves groups\n",
    "        cv = StratifiedGroupKFold(n_splits=n_folds)\n",
    "        \n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grids[model_name],\n",
    "            cv=cv,\n",
    "            scoring=scorer,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Fit grid search\n",
    "        grid_search.fit(X, y, groups=groups)\n",
    "        \n",
    "        # Store best parameters\n",
    "        best_params[model_name] = grid_search.best_params_\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "# Example usage:\n",
    "# best_params = grid_search_models(df, features)\n",
    "# print(\"\\nBest parameters for all models:\")\n",
    "# for model, params in best_params.items():\n",
    "#     print(f\"{model}: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd11af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grid Search for Random Forest ===\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    }
   ],
   "source": [
    "# === Run pipeline ===\n",
    "\n",
    "features = [col for col in df_train.columns if col not in ['id', 'sentence', 'language', 'is_root', 'group_id']]\n",
    "\n",
    "best_params = grid_search_models(df_train, features)\n",
    "\n",
    "print(\"\\nBest parameters for all models:\")\n",
    "for model, params in best_params.items():\n",
    "     print(f\"{model}: {params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f54ec8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
