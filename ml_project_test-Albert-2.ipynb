{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324e8a16",
   "metadata": {},
   "source": [
    "# üêç Machine Learning Project Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183be9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd12ce1",
   "metadata": {},
   "source": [
    "# 1. Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d76f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_csv(\"train.csv\", sep=',')\n",
    "df_train_raw[\"edgelist\"].head(1)\n",
    "df_train_raw[\"edgelist\"] = df_train_raw[\"edgelist\"].apply(ast.literal_eval)\n",
    "\n",
    "df_test_raw = pd.read_csv(\"test.csv\", sep=',')\n",
    "df_test_raw[\"edgelist\"].head(1)\n",
    "df_test_raw[\"edgelist\"] = df_test_raw[\"edgelist\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f111c7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['language', 'sentence', 'n', 'edgelist', 'root'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train_raw.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536ab68",
   "metadata": {},
   "source": [
    "# 2. Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4dd84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from community import community_louvain  # pip install python-louvain\n",
    "\n",
    "# Feature processing and normalization\n",
    "def normalize_group(df_group):\n",
    "    numeric_cols = [\n",
    "        'deg', 'degree', 'closeness', 'betweenness', 'pagerank',\n",
    "        'eigenvector', 'harmonic', 'eccentricity', \n",
    "        'clustering', 'avg_neighbor_degree', 'community'\n",
    "    ]\n",
    "    scaler = MinMaxScaler()\n",
    "    df_group[numeric_cols] = scaler.fit_transform(df_group[numeric_cols])\n",
    "    return df_group\n",
    "\n",
    "def pre_processing(data):\n",
    "    training_data = []\n",
    "    \n",
    "    for idx, row in data.iterrows():\n",
    "        edgelist = row[\"edgelist\"]\n",
    "        T = nx.Graph()\n",
    "        T.add_edges_from(edgelist)\n",
    "\n",
    "        if not nx.is_connected(T):\n",
    "            continue\n",
    "        \n",
    "        root_node = row.get(\"root\", None)\n",
    "        \n",
    "        # Essential centrality measures\n",
    "        closeness = nx.closeness_centrality(T)\n",
    "        betweenness = nx.betweenness_centrality(T)\n",
    "        pagerank = nx.pagerank(T, max_iter=1000)\n",
    "        deg_centrality = nx.degree_centrality(T)\n",
    "        \n",
    "        # Robust eigenvector computation\n",
    "        try:\n",
    "            eigenvector = nx.eigenvector_centrality(T, max_iter=10000, tol=1e-06)\n",
    "        except nx.PowerIterationFailedConvergence:\n",
    "            eigenvector = {n: 0.0 for n in T.nodes}\n",
    "            \n",
    "        harmonic = nx.harmonic_centrality(T)\n",
    "        \n",
    "        # Structural properties\n",
    "        degree = dict(T.degree())\n",
    "        eccentricity = nx.eccentricity(T)\n",
    "        clustering = nx.clustering(T)\n",
    "        avg_neighbor_degree = nx.average_neighbor_degree(T)\n",
    "        \n",
    "        # Community detection\n",
    "        partition = community_louvain.best_partition(T)\n",
    "        \n",
    "        for v in T.nodes:\n",
    "            features = {\n",
    "                \"sentence\": row[\"sentence\"],\n",
    "                \"language\": row[\"language\"],\n",
    "                \"n\": row[\"n\"],\n",
    "                \"node\": v,\n",
    "                \"deg\": deg_centrality[v],\n",
    "                \"degree\": degree[v],\n",
    "                \"closeness\": closeness[v],\n",
    "                \"betweenness\": betweenness[v],\n",
    "                \"pagerank\": pagerank[v],\n",
    "                \"eigenvector\": eigenvector[v],\n",
    "                \"harmonic\": harmonic[v],\n",
    "                \"eccentricity\": eccentricity[v],\n",
    "                \"clustering\": clustering[v],\n",
    "                \"avg_neighbor_degree\": avg_neighbor_degree[v],\n",
    "                \"community\": partition[v],\n",
    "            }\n",
    "            \n",
    "            if \"id\" in row:\n",
    "                features[\"id\"] = row[\"id\"]\n",
    "\n",
    "            if root_node is not None:\n",
    "                features[\"is_root\"] = 1 if v == root_node else 0\n",
    "\n",
    "            training_data.append(features)\n",
    "\n",
    "    training_data = pd.DataFrame(training_data)\n",
    "    \n",
    "    df_normalized = training_data.groupby([\"sentence\", \"language\"], group_keys=True).apply(\n",
    "        normalize_group, include_groups=False\n",
    "    )\n",
    "    df_normalized.reset_index(inplace=True)\n",
    "    df_normalized.drop(columns=[\"level_2\"], inplace=True)\n",
    "\n",
    "    return df_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02990071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df_train = pre_processing(df_train_raw.copy())\n",
    "features = [col for col in df_train.columns if col not in ['sentence', 'language', 'node', 'is_root', 'n', 'group_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e820604",
   "metadata": {},
   "source": [
    "# 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677bab87",
   "metadata": {},
   "source": [
    "**K-Fold Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678963a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/tania_priv/Documents/ProjectML/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <89AD948E-E564-3266-867D-7AF89D6488F0> /Users/tania_priv/Documents/ProjectML/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_recall_fscore_support\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SelectFromModel\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier \n",
      "File \u001b[0;32m~/Documents/ProjectML/.venv/lib/python3.9/site-packages/xgboost/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective, dask\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     Booster,\n\u001b[1;32m     10\u001b[0m     DataIter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     build_info,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ProjectML/.venv/lib/python3.9/site-packages/xgboost/tracker.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, make_jcargs\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ProjectML/.venv/lib/python3.9/site-packages/xgboost/core.py:269\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m _LIB \u001b[38;5;241m=\u001b[39m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m        return value from API calls\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ProjectML/.venv/lib/python3.9/site-packages/xgboost/core.py:222\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[1;32m    221\u001b[0m         libname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(lib_paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) could not be loaded.\u001b[39m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124mLikely causes:\u001b[39m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124m  * OpenMP runtime is not installed\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m \u001b[38;5;124m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[1;32m    233\u001b[0m \n\u001b[1;32m    234\u001b[0m \u001b[38;5;124mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    237\u001b[0m     _register_log_callback(lib)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(ver: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n",
      "\u001b[0;31mXGBoostError\u001b[0m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/tania_priv/Documents/ProjectML/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <89AD948E-E564-3266-867D-7AF89D6488F0> /Users/tania_priv/Documents/ProjectML/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold, RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "def enhanced_training_pipeline(df, features, n_folds=5):\n",
    "    df['group_id'] = df[\"sentence\"].astype(str) + '_' + df[\"language\"]\n",
    "    X = df[features]\n",
    "    y = df['is_root']\n",
    "    groups = df[\"group_id\"]\n",
    "\n",
    "    # Simplified hyperparameter spaces\n",
    "    models = {\n",
    "        \"RandomForest\": {\n",
    "            \"model\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "            \"params\": {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [10, 20],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [1, 2]\n",
    "            }\n",
    "        },\n",
    "        # \"XGBoost\": {\n",
    "        #     \"model\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "        #     \"params\": {\n",
    "        #         'n_estimators': [100, 200],\n",
    "        #         'max_depth': [3, 6],\n",
    "        #         'learning_rate': [0.05, 0.1],\n",
    "        #         'subsample': [0.7, 1.0]\n",
    "        #     }\n",
    "        # },\n",
    "        \"DecisionTree\": {  \n",
    "            \"model\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "            \"params\": {\n",
    "                'max_depth': [5, 10, 20],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [1, 2]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name, config in models.items():\n",
    "        print(f\"\\n=== Tuning {model_name} ===\")\n",
    "        # SMOTE resampling on entire dataset\n",
    "        smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "        X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "        # Feature selection on resampled data\n",
    "        selector = SelectFromModel(\n",
    "            estimator=RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            max_features=10\n",
    "        ).fit(X_res, y_res)\n",
    "\n",
    "        X_fs = selector.transform(X_res)\n",
    "\n",
    "        # Hyperparameter tuning on full resampled + selected features\n",
    "        search = RandomizedSearchCV(\n",
    "            config[\"model\"],\n",
    "            config[\"params\"],\n",
    "            n_iter=5,\n",
    "            scoring='f1',\n",
    "            cv=3,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        search.fit(X_fs, y_res)\n",
    "        best_params = search.best_params_\n",
    "\n",
    "        print(f\"Best params found: {best_params}\")\n",
    "\n",
    "        # Now perform cross-validation with fixed best params\n",
    "        fold_metrics = {'acc': [], 'prec': [], 'rec': [], 'f1': []}\n",
    "        cv = StratifiedGroupKFold(n_splits=n_folds)\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X, y, groups=groups):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            # Apply SMOTE on training fold only\n",
    "            smote_fold = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "            X_train_res, y_train_res = smote_fold.fit_resample(X_train, y_train)\n",
    "\n",
    "            # Apply previously fit selector to training and validation\n",
    "            X_train_fs = selector.transform(X_train_res)\n",
    "            X_val_fs = selector.transform(X_val)\n",
    "\n",
    "            # Train model with best hyperparameters\n",
    "            model = config[\"model\"].set_params(**best_params)\n",
    "            model.fit(X_train_fs, y_train_res)\n",
    "\n",
    "            # Prepare val_df for evaluation\n",
    "            val_df = df.iloc[val_idx].copy()\n",
    "            val_df['proba'] = model.predict_proba(X_val_fs)[:, 1]\n",
    "\n",
    "            predicted_roots = val_df.loc[val_df.groupby(['sentence', 'language'])['proba'].idxmax()]\n",
    "            true_roots = val_df[val_df['is_root'] == 1]\n",
    "\n",
    "            merged = predicted_roots.merge(\n",
    "                true_roots,\n",
    "                on=['sentence', 'language'],\n",
    "                suffixes=('_pred', '_true')\n",
    "            )\n",
    "\n",
    "            correct = merged['node_pred'] == merged['node_true']\n",
    "            acc = correct.mean()\n",
    "            prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "                correct, [True] * len(correct), average='binary'\n",
    "            )\n",
    "\n",
    "            fold_metrics['acc'].append(acc)\n",
    "            fold_metrics['prec'].append(prec)\n",
    "            fold_metrics['rec'].append(rec)\n",
    "            fold_metrics['f1'].append(f1)\n",
    "\n",
    "        results[model_name] = {\n",
    "            'mean_f1': np.mean(fold_metrics['f1']),\n",
    "            'mean_precision': np.mean(fold_metrics['prec']),\n",
    "            'mean_recall': np.mean(fold_metrics['rec']),\n",
    "            'best_params': best_params,\n",
    "            'selector': selector\n",
    "        }\n",
    "\n",
    "        print(f\"Mean F1: {results[model_name]['mean_f1']:.4f}\")\n",
    "\n",
    "    # Train final model on full dataset with best model and best params\n",
    "    best_model_name = max(results.items(), key=lambda x: x[1]['mean_f1'])[0]\n",
    "    best_config = models[best_model_name]\n",
    "    best_params = results[best_model_name]['best_params']\n",
    "    final_selector = results[best_model_name]['selector']\n",
    "\n",
    "    print(f\"\\nTraining final {best_model_name} model...\")\n",
    "\n",
    "    smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "    X_res, y_res = smote.fit_resample(X, y)\n",
    "    X_fs = final_selector.transform(X_res)\n",
    "\n",
    "    final_model = best_config[\"model\"].set_params(**best_params)\n",
    "    final_model.fit(X_fs, y_res)\n",
    "\n",
    "    return results, best_model_name, final_model, final_selector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd3e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuning RandomForest ===\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "results, best_model_name, best_model, feature_selector = enhanced_training_pipeline(df_train, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process test data\n",
    "df_test_processed = pre_processing(df_test_raw.copy())\n",
    "X_test = df_test_processed[features]\n",
    "X_test_fs = feature_selector.transform(X_test)\n",
    "\n",
    "# Predict\n",
    "df_test_processed['pred_proba'] = best_model.predict_proba(X_test_fs)[:, 1]\n",
    "predicted_roots = df_test_processed.loc[\n",
    "    df_test_processed.groupby('id')['pred_proba'].idxmax()\n",
    "]\n",
    "\n",
    "# Format output\n",
    "output_df = predicted_roots[['id', 'node']].rename(columns={'node': 'root'})\n",
    "output_df = output_df.sort_values('id').reset_index(drop=True)\n",
    "output_df.to_csv('predicted_roots.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f54ec8",
   "metadata": {},
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c04c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
